{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a20e8a",
   "metadata": {},
   "source": [
    "# Apply posterior reweighting\n",
    "\n",
    "mention in paper: skew-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1464a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "from fair import __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_v = dotenv_values(\"../../../.env\")[\"CALIBRATION_VERSION\"]\n",
    "samples = int(dotenv_values(\"../../../.env\")[\"PRIOR_SAMPLES\"])\n",
    "output_ensemble_size = int(dotenv_values(\"../../../.env\")[\"POSTERIOR_SAMPLES\"])\n",
    "fair_v = dotenv_values(\"../../../.env\")[\"FAIR_VERSION\"]\n",
    "constraint_set = dotenv_values(\"../../../.env\")[\"CONSTRAINT_SET\"]\n",
    "\n",
    "assert fair_v == __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac79e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pl.rcParams['figure.figsize'] = (11.4, 11.4)\n",
    "# pl.rcParams['font.size'] = 16\n",
    "# pl.rcParams['font.family'] = 'Arial'\n",
    "# pl.rcParams['ytick.direction'] = 'in'\n",
    "# pl.rcParams['ytick.minor.visible'] = True\n",
    "# pl.rcParams['ytick.major.right'] = True\n",
    "# pl.rcParams['ytick.right'] = True\n",
    "# pl.rcParams['xtick.direction'] = 'in'\n",
    "# pl.rcParams['xtick.minor.visible'] = True\n",
    "# pl.rcParams['xtick.major.top'] = True\n",
    "# pl.rcParams['xtick.top'] = True\n",
    "# pl.rcParams['axes.spines.top'] = True\n",
    "# pl.rcParams['axes.spines.bottom'] = True\n",
    "# pl.rcParams['figure.dpi'] = 150\n",
    "# pl.rcParams['lines.linewidth'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346cb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "NINETY_TO_ONESIGMA = scipy.stats.norm.ppf(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_temp = np.loadtxt(f'../../../output/fair-{fair_v}/v{cal_v}/posteriors/{constraint_set}/runids_rmse_pass.csv').astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ensemble_size = len(valid_temp)\n",
    "input_ensemble_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198700e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert input_ensemble_size > output_ensemble_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_in = np.load(f'../../../output/fair-{fair_v}/v{cal_v}/prior_runs/temperature_1850-2101.npy')\n",
    "ohc_in = np.load(f'../../../output/fair-{fair_v}/v{cal_v}/prior_runs/ocean_heat_content_2018_minus_1971.npy')\n",
    "fari_in = np.load(f'../../../output/fair-{fair_v}/v{cal_v}/prior_runs/forcing_ari_2005-2014_mean.npy')\n",
    "faci_in = np.load(f'../../../output/fair-{fair_v}/v{cal_v}/prior_runs/forcing_aci_2005-2014_mean.npy')\n",
    "co2_in = np.load(f'../../../output/fair-{fair_v}/v{cal_v}/prior_runs/concentration_co2_2014.npy')\n",
    "ecs_in = np.load(f'../../../output/fair-{fair_v}/v{cal_v}/prior_runs/ecs.npy')\n",
    "tcr_in = np.load(f'../../../output/fair-{fair_v}/v{cal_v}/prior_runs/tcr.npy')\n",
    "faer_in = fari_in + faci_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22952f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt(x, q05_desired, q50_desired, q95_desired):\n",
    "    \"x is (a, loc, scale) in that order.\"\n",
    "    q05, q50, q95 = scipy.stats.skewnorm.ppf((0.05, 0.50, 0.95), x[0], loc=x[1], scale=x[2])\n",
    "    #print(q05, q50, q95, x)\n",
    "    return (q05-q05_desired, q50-q50_desired, q95-q95_desired)\n",
    "    \n",
    "#scipy.optimize.root(opt, (2.0, 2.6, 1.2), (1.24, 1.81, 2.59), options={'maxfev': 5000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.optimize.root(opt, (1, 0.85, 1), (0.69, 0.85, 0.98), options={'maxfev': 5000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec88727",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {}\n",
    "samples['ECS'] = scipy.stats.skewnorm.rvs(8.82185594, loc=1.95059779, scale=1.55584604, size=10**5, random_state=91603)\n",
    "samples['TCR'] = scipy.stats.norm.rvs(loc=1.8, scale=0.6/NINETY_TO_ONESIGMA, size=10**5, random_state=18196)\n",
    "samples['OHC'] = scipy.stats.norm.rvs(loc=434.3730268913012, scale=73.70562981598447, size=10**5, random_state=43178)\n",
    "samples['temperature 1995-2014'] = scipy.stats.skewnorm.rvs(-1.65506091, loc=0.92708099, scale=0.12096636, size=10**5, random_state=19387)\n",
    "samples['temperature 2081-2100'] = scipy.stats.skewnorm.rvs(2.20496701, loc=1.4124379, scale=0.60080822, size=10**5, random_state=91831)\n",
    "samples['ERFari'] = scipy.stats.norm.rvs(loc=-0.3, scale=0.3/NINETY_TO_ONESIGMA, size=10**5, random_state=70173)\n",
    "samples['ERFaci'] = scipy.stats.norm.rvs(loc=-1.0, scale=0.7/NINETY_TO_ONESIGMA, size=10**5, random_state=91123)\n",
    "samples['ERFaer'] = scipy.stats.norm.rvs(loc=-1.3, scale=np.sqrt(0.7**2+0.3**2)/NINETY_TO_ONESIGMA, size=10**5, random_state=3916153)\n",
    "samples['CO2 concentration'] = scipy.stats.norm.rvs(loc=397.5469792683919, scale=0.36, size=10**5, random_state=81693)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08236194",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa144c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.hist(samples['ECS'], bins=100, alpha=0.5, label='Target distribution', density=True)\n",
    "# pl.hist(ecs_in[valid_temp], bins=100, alpha=0.5, label='RMSE < 0.16 K posterior', density=True)\n",
    "# pl.legend()\n",
    "# print('target distribution:', np.percentile(samples['ECS'], (5, 16, 50, 84, 95)))\n",
    "# print('naive constraints:', np.percentile(ecs_in[valid_temp], (5, 16, 50, 84, 95)))\n",
    "# pl.title('Equilibrium climate sensitivity')\n",
    "# pl.xlim(0, 8)\n",
    "# pl.ylabel('Density')\n",
    "# pl.xlabel('deg C')\n",
    "# # pl.savefig('../plots/reweighting.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_distributions = {}\n",
    "for constraint in ['ECS', 'TCR', 'OHC', 'temperature 1995-2014', 'temperature 2081-2100', 'ERFari', 'ERFaci', 'ERFaer', 'CO2 concentration']:\n",
    "    ar_distributions[constraint] = {}\n",
    "    ar_distributions[constraint]['bins'] = np.histogram(samples[constraint], bins=200, density=True)[1]\n",
    "    ar_distributions[constraint]['values'] = samples[constraint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93dcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_20yr = np.ones(21)\n",
    "weights_20yr[0] = 0.5\n",
    "weights_20yr[-1] = 0.5\n",
    "weights_51yr = np.ones(52)\n",
    "weights_51yr[0] = 0.5\n",
    "weights_51yr[-1] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ffa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted = pd.DataFrame(\n",
    "    {\n",
    "        'ECS': ecs_in[valid_temp],\n",
    "        'TCR': tcr_in[valid_temp],\n",
    "        'OHC': ohc_in[valid_temp]/1e21,\n",
    "        'temperature 1995-2014': np.average(temp_in[145:166,valid_temp], weights=weights_20yr, axis=0) - np.average(temp_in[:52,valid_temp], weights=weights_51yr, axis=0),\n",
    "        'temperature 2081-2100': np.average(temp_in[231:252,valid_temp], weights=weights_20yr, axis=0) - np.average(temp_in[145:166,valid_temp], weights=weights_20yr, axis=0),\n",
    "        'ERFari': fari_in[valid_temp],\n",
    "        'ERFaci': faci_in[valid_temp],\n",
    "        'ERFaer': faer_in[valid_temp],\n",
    "        'CO2 concentration': co2_in[valid_temp]\n",
    "    },\n",
    "    index=valid_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_weights(distributions, samples, niterations=50):\n",
    "    #weights = np.ones(samples[list(accepted.keys())[0]].shape[0])\n",
    "    weights = np.ones(samples.shape[0])\n",
    "    gofs = []\n",
    "    gofs_full = []\n",
    "\n",
    "    unique_codes = list(distributions.keys())#[::-1]\n",
    "\n",
    "    for k in tqdm(range(niterations), desc=\"Iterations\", leave=False):\n",
    "        gofs.append([])\n",
    "        if k == (niterations - 1):\n",
    "            weights_second_last_iteration = weights.copy()\n",
    "            weights_to_average = []\n",
    "            \n",
    "        for j, unique_code in enumerate(unique_codes):\n",
    "            unique_code_weights, our_values_bin_idx = get_unique_code_weights(\n",
    "                unique_code, distributions, samples, weights, j, k\n",
    "            )\n",
    "            if k == (niterations - 1):\n",
    "                weights_to_average.append(unique_code_weights[our_values_bin_idx])\n",
    "        \n",
    "            weights *= unique_code_weights[our_values_bin_idx]\n",
    "            \n",
    "            gof = ((unique_code_weights[1:-1] - 1) ** 2).sum()\n",
    "            gofs[-1].append(gof)\n",
    "               \n",
    "            gofs_full.append([unique_code])\n",
    "            for unique_code_check in unique_codes:\n",
    "                unique_code_check_weights, _ = get_unique_code_weights(\n",
    "                    unique_code_check, distributions, samples, weights, 1, 1\n",
    "                )\n",
    "                gof = ((unique_code_check_weights[1:-1] - 1) ** 2).sum()\n",
    "                gofs_full[-1].append(gof)\n",
    "\n",
    "    weights_stacked = np.vstack(weights_to_average).mean(axis=0)\n",
    "    weights_final = weights_stacked * weights_second_last_iteration\n",
    "\n",
    "    gofs_full.append([\"Final iteration\"])\n",
    "    for unique_code_check in unique_codes:\n",
    "        unique_code_check_weights, _ = get_unique_code_weights(\n",
    "            unique_code_check, distributions, samples, weights_final, 1, 1\n",
    "        )\n",
    "        gof = ((unique_code_check_weights[1:-1] - 1) ** 2).sum()\n",
    "        gofs_full[-1].append(gof)\n",
    "\n",
    "    return (\n",
    "        weights_final, \n",
    "        pd.DataFrame(np.array(gofs), columns=unique_codes), \n",
    "        pd.DataFrame(np.array(gofs_full), columns=[\"Target marginal\"] + unique_codes)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb47287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_code_weights(unique_code, distributions, samples, weights, j, k):\n",
    "    bin_edges = distributions[unique_code][\"bins\"]\n",
    "    our_values = samples[unique_code].copy()\n",
    "\n",
    "    our_values_bin_counts, bin_edges_np = np.histogram(\n",
    "        our_values, bins=bin_edges\n",
    "    )\n",
    "    np.testing.assert_allclose(bin_edges, bin_edges_np)\n",
    "    assessed_ranges_bin_counts, _ = np.histogram(\n",
    "        distributions[unique_code][\"values\"], bins=bin_edges\n",
    "    )\n",
    "    \n",
    "    our_values_bin_idx = np.digitize(our_values, bins=bin_edges)\n",
    "\n",
    "    existing_weighted_bin_counts = np.nan * np.zeros(\n",
    "        our_values_bin_counts.shape[0]\n",
    "    )\n",
    "    for i in range(existing_weighted_bin_counts.shape[0]):\n",
    "        existing_weighted_bin_counts[i] = weights[\n",
    "            (our_values_bin_idx == i + 1)\n",
    "        ].sum()\n",
    "\n",
    "    if np.equal(j, 0) and np.equal(k, 0):\n",
    "        np.testing.assert_equal(\n",
    "            existing_weighted_bin_counts.sum(), our_values_bin_counts.sum()\n",
    "        )\n",
    "\n",
    "    unique_code_weights = np.nan * np.zeros(bin_edges.shape[0] + 1)\n",
    "\n",
    "    # existing_weighted_bin_counts[0] refers to samples outside the\n",
    "    # assessed range's lower bound. Accordingly, if `our_values` was\n",
    "    # digitized into a bin idx of zero, it should get a weight of zero.\n",
    "    unique_code_weights[0] = 0\n",
    "    # Similarly, if `our_values` was digitized into a bin idx greater\n",
    "    # than the number of bins then it was outside the assessed range\n",
    "    # so get a weight of zero.\n",
    "    unique_code_weights[-1] = 0\n",
    "    \n",
    "    for i in range(1, our_values_bin_counts.shape[0] + 1):\n",
    "        # the histogram idx is one less because digitize gives values in the\n",
    "        # range bin_edges[0] <= x < bin_edges[1] a digitized index of 1\n",
    "        histogram_idx = i - 1\n",
    "        if np.equal(assessed_ranges_bin_counts[histogram_idx], 0):\n",
    "            unique_code_weights[i] = 0\n",
    "        elif np.equal(existing_weighted_bin_counts[histogram_idx], 0):\n",
    "            # other variables force this box to be zero so just fill it with\n",
    "            # one\n",
    "            unique_code_weights[i] = 1\n",
    "        else:\n",
    "            unique_code_weights[i] = (\n",
    "                assessed_ranges_bin_counts[histogram_idx]\n",
    "                / existing_weighted_bin_counts[histogram_idx]\n",
    "            )\n",
    "            \n",
    "    return unique_code_weights, our_values_bin_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d348549",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, gofs, gofs_full = calculate_sample_weights(\n",
    "    ar_distributions, accepted, niterations=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1079528",
   "metadata": {},
   "outputs": [],
   "source": [
    "gofs_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_samples = int(np.floor(np.sum(np.minimum(weights, 1))))\n",
    "effective_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = []\n",
    "\n",
    "drawn_samples = accepted.sample(n=output_ensemble_size, replace=False, weights=weights, random_state=10099)\n",
    "draws.append((drawn_samples))\n",
    "\n",
    "#for i in tqdman.tqdm(range(10)):\n",
    "#    drawn_samples = accepted.sample(n=OUTPUT_ENSEMBLE_SIZE, replace=False, weights=weights, random_state=)\n",
    "    #     drawn_samples = samples_df.sample(n=10, replace=False, weights=weights)\n",
    "\n",
    "    #summary_table = get_summary_table(drawn_samples)\n",
    "\n",
    "    #score, coloured_df = utils.plotting.colour_df(summary_table, transpose=True)\n",
    "\n",
    "#    draws.append((drawn_samples))\n",
    "\n",
    "#sorted([v[1] for v in draws])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "draws[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39099cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(draws[0]['temperature 1995-2014'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ecs = scipy.stats.gaussian_kde(samples['ECS'])\n",
    "prior_ecs = scipy.stats.gaussian_kde(ecs_in)\n",
    "post1_ecs = scipy.stats.gaussian_kde(ecs_in[valid_temp])\n",
    "post2_ecs = scipy.stats.gaussian_kde(draws[0]['ECS'])\n",
    "\n",
    "target_tcr = scipy.stats.gaussian_kde(samples['TCR'])\n",
    "prior_tcr = scipy.stats.gaussian_kde(tcr_in)\n",
    "post1_tcr = scipy.stats.gaussian_kde(tcr_in[valid_temp])\n",
    "post2_tcr = scipy.stats.gaussian_kde(draws[0]['TCR'])\n",
    "\n",
    "target_temp = scipy.stats.gaussian_kde(samples['temperature 1995-2014'])\n",
    "prior_temp = scipy.stats.gaussian_kde(temp_in[145:165, :].mean(axis=0))\n",
    "post1_temp = scipy.stats.gaussian_kde(temp_in[145:165, valid_temp].mean(axis=0))\n",
    "post2_temp = scipy.stats.gaussian_kde(draws[0]['temperature 1995-2014'])\n",
    "\n",
    "target_ohc = scipy.stats.gaussian_kde(samples['OHC'])\n",
    "prior_ohc = scipy.stats.gaussian_kde(ohc_in/1e21)\n",
    "post1_ohc = scipy.stats.gaussian_kde(ohc_in[valid_temp]/1e21)\n",
    "post2_ohc = scipy.stats.gaussian_kde(draws[0]['OHC'])\n",
    "\n",
    "target_aer = scipy.stats.gaussian_kde(samples['ERFaer'])\n",
    "prior_aer = scipy.stats.gaussian_kde(faer_in)\n",
    "post1_aer = scipy.stats.gaussian_kde(faer_in[valid_temp])\n",
    "post2_aer = scipy.stats.gaussian_kde(draws[0]['ERFaer'])\n",
    "\n",
    "target_aci = scipy.stats.gaussian_kde(samples['ERFaci'])\n",
    "prior_aci = scipy.stats.gaussian_kde(faci_in)\n",
    "post1_aci = scipy.stats.gaussian_kde(faci_in[valid_temp])\n",
    "post2_aci = scipy.stats.gaussian_kde(draws[0]['ERFaci'])\n",
    "\n",
    "target_ari = scipy.stats.gaussian_kde(samples['ERFari'])\n",
    "prior_ari = scipy.stats.gaussian_kde(fari_in)\n",
    "post1_ari = scipy.stats.gaussian_kde(fari_in[valid_temp])\n",
    "post2_ari = scipy.stats.gaussian_kde(draws[0]['ERFari'])\n",
    "\n",
    "target_co2 = scipy.stats.gaussian_kde(samples['CO2 concentration'])\n",
    "prior_co2 = scipy.stats.gaussian_kde(co2_in)\n",
    "post1_co2 = scipy.stats.gaussian_kde(co2_in[valid_temp])\n",
    "post2_co2 = scipy.stats.gaussian_kde(draws[0]['CO2 concentration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d664d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'prior': '#207F6E',\n",
    "    'post1': '#684C94',\n",
    "    'post2': '#EE696B',\n",
    "    'target': 'black'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c8f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = pl.subplots(2,3, figsize=(15, 10))\n",
    "start = 0\n",
    "stop = 8\n",
    "ax[0,0].plot(np.linspace(start, stop, 1000), prior_ecs(np.linspace(start, stop, 1000)), color=colors['prior'], label='Prior')\n",
    "ax[0,0].plot(np.linspace(start, stop, 1000), post1_ecs(np.linspace(start, stop, 1000)), color=colors['post1'], label='Temperature RMSE')\n",
    "ax[0,0].plot(np.linspace(start, stop, 1000), post2_ecs(np.linspace(start, stop, 1000)), color=colors['post2'], label='All constraints')\n",
    "ax[0,0].plot(np.linspace(start, stop, 1000), target_ecs(np.linspace(start, stop, 1000)), color=colors['target'], label='Target')\n",
    "ax[0,0].set_xlim(start, stop)\n",
    "ax[0,0].set_ylim(0, 0.5)\n",
    "ax[0,0].set_title('ECS')\n",
    "ax[0,0].set_yticklabels([])\n",
    "ax[0,0].set_xlabel('째C')\n",
    "\n",
    "start = 0\n",
    "stop = 4\n",
    "ax[0,1].plot(np.linspace(start, stop, 1000), prior_tcr(np.linspace(start, stop, 1000)), color=colors['prior'], label='Prior')\n",
    "ax[0,1].plot(np.linspace(start, stop, 1000), post1_tcr(np.linspace(start, stop, 1000)), color=colors['post1'], label='Temperature RMSE')\n",
    "ax[0,1].plot(np.linspace(start, stop, 1000), post2_tcr(np.linspace(start, stop, 1000)), color=colors['post2'], label='All constraints')\n",
    "ax[0,1].plot(np.linspace(start, stop, 1000), target_tcr(np.linspace(start, stop, 1000)), color=colors['target'], label='Target')\n",
    "ax[0,1].set_xlim(start, stop)\n",
    "ax[0,1].set_ylim(0, 1.2)\n",
    "ax[0,1].set_title('TCR')\n",
    "ax[0,1].set_yticklabels([])\n",
    "ax[0,1].set_xlabel('째C')\n",
    "\n",
    "start = 0.5\n",
    "stop = 1.3\n",
    "ax[0,2].plot(np.linspace(start, stop, 1000), target_temp(np.linspace(start, stop, 1000)), color=colors['target'], label='Target')\n",
    "ax[0,2].plot(np.linspace(start, stop, 1000), prior_temp(np.linspace(start, stop, 1000)), color=colors['prior'], label='Prior')\n",
    "ax[0,2].plot(np.linspace(start, stop, 1000), post1_temp(np.linspace(start, stop, 1000)), color=colors['post1'], label='Temperature RMSE')\n",
    "ax[0,2].plot(np.linspace(start, stop, 1000), post2_temp(np.linspace(start, stop, 1000)), color=colors['post2'], label='All constraints')\n",
    "ax[0,2].set_xlim(start, stop)\n",
    "ax[0,2].set_ylim(0, 5)\n",
    "ax[0,2].set_title('Temperature anomaly')\n",
    "ax[0,2].set_yticklabels([])\n",
    "ax[0,2].set_xlabel('째C, 1995-2014 minus 1850-1900')\n",
    "\n",
    "# start = -2.5\n",
    "# stop = 0\n",
    "# ax[1,0].plot(np.linspace(start, stop), target_aer(np.linspace(start, stop)), label='Target distribution')\n",
    "# ax[1,0].plot(np.linspace(start, stop), prior_aer(np.linspace(start, stop)), label='RMSE < 0.16 K posterior')\n",
    "# ax[1,0].plot(np.linspace(start, stop), post_aer(np.linspace(start, stop)))\n",
    "# ax[1,0].set_xlim(start, stop)\n",
    "# ax[1,0].set_ylim(0, 1.2)\n",
    "\n",
    "start = -3\n",
    "stop = 0\n",
    "ax[1,0].plot(np.linspace(start, stop, 1000), target_aer(np.linspace(start, stop, 1000)), color=colors['target'], label='Target')\n",
    "ax[1,0].plot(np.linspace(start, stop, 1000), prior_aer(np.linspace(start, stop, 1000)), color=colors['prior'], label='Prior')\n",
    "ax[1,0].plot(np.linspace(start, stop, 1000), post1_aer(np.linspace(start, stop, 1000)), color=colors['post1'], label='Temperature RMSE')\n",
    "ax[1,0].plot(np.linspace(start, stop, 1000), post2_aer(np.linspace(start, stop, 1000)), color=colors['post2'], label='All constraints')\n",
    "ax[1,0].set_xlim(start, stop)\n",
    "ax[1,0].set_ylim(0, 1.6)\n",
    "ax[1,0].set_title('Aerosol ERF')\n",
    "ax[1,0].legend(frameon=False, loc='upper left')\n",
    "ax[1,0].set_yticklabels([])\n",
    "ax[1,0].set_xlabel('W m$^{-2}$, 2005-2014 minus 1750')\n",
    "\n",
    "start = 394\n",
    "stop = 402\n",
    "ax[1,1].plot(np.linspace(start, stop, 1000), target_co2(np.linspace(start, stop, 1000)), color=colors['target'], label='Target')\n",
    "ax[1,1].plot(np.linspace(start, stop, 1000), prior_co2(np.linspace(start, stop, 1000)), color=colors['prior'], label='Prior')\n",
    "ax[1,1].plot(np.linspace(start, stop, 1000), post1_co2(np.linspace(start, stop, 1000)), color=colors['post1'], label='Temperature RMSE')\n",
    "ax[1,1].plot(np.linspace(start, stop, 1000), post2_co2(np.linspace(start, stop, 1000)), color=colors['post2'], label='All constraints')\n",
    "ax[1,1].set_xlim(start, stop)\n",
    "ax[1,1].set_ylim(0, 1.2)\n",
    "ax[1,1].set_title('CO$_2$ concentration')\n",
    "ax[1,1].set_yticklabels([])\n",
    "ax[1,1].set_xlabel('ppm, 2014')\n",
    "\n",
    "start = 0\n",
    "stop = 800\n",
    "ax[1,2].plot(np.linspace(start, stop), target_ohc(np.linspace(start, stop)), color=colors['target'], label='Target')\n",
    "ax[1,2].plot(np.linspace(start, stop), prior_ohc(np.linspace(start, stop)), color=colors['prior'], label='Prior')\n",
    "ax[1,2].plot(np.linspace(start, stop), post1_ohc(np.linspace(start, stop)), color=colors['post1'], label='Temperature RMSE')\n",
    "ax[1,2].plot(np.linspace(start, stop), post2_ohc(np.linspace(start, stop)), color=colors['post2'], label='All constraints')\n",
    "ax[1,2].set_xlim(start, stop)\n",
    "ax[1,2].set_ylim(0, .006)\n",
    "ax[1,2].set_title('Ocean heat content change')\n",
    "ax[1,2].set_yticklabels([])\n",
    "ax[1,2].set_xlabel('ZJ, 2018 minus 1971')\n",
    "#ax[0,1].hist(samples['TCR'], bins=100, alpha=0.5, label='Target distribution', density=True)\n",
    "#ax[0,1].hist(tcr_in[valid_temp], bins=100, alpha=0.5, label='RMSE < 0.16 K posterior', density=True);\n",
    "#ax[0,1].hist(draws[0]['TCR'], bins=100, alpha=0.5, density=True);\n",
    "#ax[0,0].hist(samples['ECS'], bins=100, alpha=0.5, label='Target distribution', density=True)\n",
    "#ax[0,0].hist(ecs_in[valid_temp], bins=100, alpha=0.5, label='RMSE < 0.16 K posterior', density=True)\n",
    "\n",
    "fig.tight_layout()\n",
    "# pl.savefig('../plots/constraints.png')\n",
    "# pl.savefig('../plots/constraints.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(draws[0]['ECS'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69489d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(draws[0]['TCR'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scatter(draws[0]['TCR'], draws[0]['ECS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(draws[0]['CO2 concentration'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(draws[0]['temperature 1995-2014'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(draws[0]['ERFari'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66348d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(draws[0]['ERFaci'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b958730",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(draws[0]['ERFaci']+draws[0]['ERFari'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efc0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(draws[0]['OHC'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scatter(draws[0]['TCR'], draws[0]['ERFaci']+draws[0]['ERFari'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "draws[0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc03bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gmst = pd.read_csv('../../../data/forcing/AR6_GMST.csv')\n",
    "gmst = df_gmst['gmst'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(figsize=(5, 5))\n",
    "ax.fill_between(\n",
    "    np.arange(1850, 2102), \n",
    "    np.min(temp_in[:,draws[0].index]-np.average(temp_in[:52,draws[0].index], weights=weights_51yr, axis=0), axis=1), \n",
    "    np.max(temp_in[:,draws[0].index]-np.average(temp_in[:52,draws[0].index], weights=weights_51yr, axis=0), axis=1),\n",
    "    color='#000000',\n",
    "    alpha=0.2,\n",
    ")\n",
    "ax.fill_between(\n",
    "    np.arange(1850, 2102), \n",
    "    np.percentile(temp_in[:,draws[0].index]-np.average(temp_in[:52,draws[0].index], weights=weights_51yr, axis=0), 5, axis=1), \n",
    "    np.percentile(temp_in[:,draws[0].index]-np.average(temp_in[:52,draws[0].index], weights=weights_51yr, axis=0), 95, axis=1),\n",
    "    color='#000000',\n",
    "    alpha=0.2,\n",
    ")\n",
    "ax.fill_between(\n",
    "    np.arange(1850, 2102), \n",
    "    np.percentile(temp_in[:,draws[0].index]-np.average(temp_in[:52,draws[0].index], weights=weights_51yr, axis=0), 16, axis=1), \n",
    "    np.percentile(temp_in[:,draws[0].index]-np.average(temp_in[:52,draws[0].index], weights=weights_51yr, axis=0), 84, axis=1),\n",
    "    color='#000000',\n",
    "    alpha=0.2,\n",
    ")\n",
    "ax.plot(\n",
    "    np.arange(1850, 2102), \n",
    "    np.median(temp_in[:,draws[0].index]-np.average(temp_in[:52,draws[0].index], weights=weights_51yr, axis=0), axis=1), \n",
    "    color='#000000',\n",
    ")\n",
    "\n",
    "ax.plot(np.arange(1850.5, 2021), gmst, color='b', label='Observations')\n",
    "\n",
    "ax.legend(frameon=False, loc='upper left')\n",
    "\n",
    "ax.set_xlim(1850,2100)\n",
    "ax.set_ylim(-1, 5)\n",
    "ax.set_ylabel('째C relative to 1850-1900')\n",
    "ax.axhline(0, color='k', ls=\":\", lw=0.5)\n",
    "pl.tight_layout()\n",
    "#pl.title('constrained & reweighted (1001)')\n",
    "#pl.savefig('../plots/final_reweighted_ssp245.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb01452",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'../../../output/fair-{fair_v}/v{cal_v}/posteriors/{constraint_set}/runids_rmse_reweighted_pass.csv', sorted(draws[0].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07045a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

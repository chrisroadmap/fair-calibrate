{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1464a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "import tqdm.autonotebook as tqdman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346cb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_ENSEMBLE_SIZE = 1001\n",
    "NINETY_TO_ONESIGMA = scipy.stats.norm.ppf(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_temp = np.loadtxt('../data/ar6_ensemble_batches_rcp/accepted_rmse_temp.csv', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ensemble_size = len(valid_temp)\n",
    "input_ensemble_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198700e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert input_ensemble_size > OUTPUT_ENSEMBLE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_in = np.load('../data/ar6_ensemble_batches_rcp/temperature_1850-2100.npy')\n",
    "ohc_in = np.load('../data/ar6_ensemble_batches_rcp/ohc_2018_minus_1971.npy')\n",
    "fari_in = np.load('../data/ar6_ensemble_batches_rcp/fari_2005-2014_mean.npy')\n",
    "faci_in = np.load('../data/ar6_ensemble_batches_rcp/faci_2005-2014_mean.npy')\n",
    "co2_in = np.load('../data/ar6_ensemble_batches_rcp/co2_2014.npy')\n",
    "ecs_in = np.load('../data/ar6_ensemble_batches_rcp/ecs.npy')\n",
    "tcr_in = np.load('../data/ar6_ensemble_batches_rcp/tcr.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22952f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt(x, q05_desired, q50_desired, q95_desired):\n",
    "    \"x is (a, loc, scale) in that order.\"\n",
    "    q05, q50, q95 = scipy.stats.skewnorm.ppf((0.05, 0.50, 0.95), x[0], loc=x[1], scale=x[2])\n",
    "    #print(q05, q50, q95, x)\n",
    "    return (q05-q05_desired, q50-q50_desired, q95-q95_desired)\n",
    "    \n",
    "scipy.optimize.root(opt, (2.0, 2.6, 1.2), (1.24, 1.81, 2.59), options={'maxfev': 5000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec88727",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {}\n",
    "samples['ECS'] = scipy.stats.skewnorm.rvs(8.82185594, loc=1.95059779, scale=1.55584604, size=10**5, random_state=91603)\n",
    "samples['TCR'] = scipy.stats.norm.rvs(loc=1.8, scale=0.6/NINETY_TO_ONESIGMA, size=10**5, random_state=18196)\n",
    "samples['OHC'] = scipy.stats.norm.rvs(loc=434.3730268913012, scale=73.70562981598447, size=10**5, random_state=43178)\n",
    "samples['temperature 1995-2014'] = scipy.stats.skewnorm.rvs(-1.65506091, loc=0.92708099, scale=0.12096636, size=10**5, random_state=19387)\n",
    "#samples['temperature 2081-2100'] = scipy.stats.skewnorm.rvs(2.20496701, loc=1.4124379, scale=0.60080822, size=10**5, random_state=91831)\n",
    "samples['ERFari'] = scipy.stats.norm.rvs(loc=-0.3, scale=0.3/NINETY_TO_ONESIGMA, size=10**5, random_state=70173)\n",
    "samples['ERFaci'] = scipy.stats.norm.rvs(loc=-1.0, scale=0.7/NINETY_TO_ONESIGMA, size=10**5, random_state=91123)\n",
    "samples['CO2 concentration'] = scipy.stats.norm.rvs(loc=397.5469792683919, scale=0.36, size=10**5, random_state=81693)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa144c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(samples['ECS'], bins=100, alpha=0.5, label='Sampled', density=True)\n",
    "pl.hist(ecs_in[valid_temp], bins=100, alpha=0.5, label='Naive constraints', density=True)\n",
    "pl.legend()\n",
    "print('target distribution:', np.percentile(samples['ECS'], (5, 16, 50, 84, 95)))\n",
    "print('naive constraints:', np.percentile(ecs_in[valid_temp], (5, 16, 50, 84, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_distributions = {}\n",
    "#for constraint in ['ECS', 'TCR', 'OHC', 'temperature 1995-2014', 'temperature 2081-2100', 'ERFari', 'ERFaci', 'CO2 concentration']:\n",
    "for constraint in ['ECS', 'TCR', 'OHC', 'temperature 1995-2014', 'ERFari', 'ERFaci', 'CO2 concentration']:\n",
    "    ar_distributions[constraint] = {}\n",
    "    ar_distributions[constraint]['bins'] = np.histogram(samples[constraint], bins=100, density=True)[1]\n",
    "    ar_distributions[constraint]['values'] = samples[constraint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ffa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted = pd.DataFrame(\n",
    "    {\n",
    "        'ECS': ecs_in[valid_temp],\n",
    "        'TCR': tcr_in[valid_temp],\n",
    "        'OHC': ohc_in[valid_temp]/1e21,\n",
    "        'temperature 1995-2014': temp_in[145:165,valid_temp].mean(axis=0) - temp_in[:51,valid_temp].mean(axis=0),\n",
    "#        'temperature 2081-2100': temp_in[231:251,valid_temp].mean(axis=0) - temp_in[145:165,valid_temp].mean(axis=0),\n",
    "        'ERFari': fari_in[valid_temp],\n",
    "        'ERFaci': faci_in[valid_temp],\n",
    "        'CO2 concentration': co2_in[valid_temp]\n",
    "    },\n",
    "    index=valid_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_weights(distributions, samples, niterations=50):\n",
    "    #weights = np.ones(samples[list(accepted.keys())[0]].shape[0])\n",
    "    weights = np.ones(samples.shape[0])\n",
    "    gofs = []\n",
    "    gofs_full = []\n",
    "\n",
    "    unique_codes = list(distributions.keys())#[::-1]\n",
    "\n",
    "    for k in tqdman.tqdm(range(niterations), desc=\"Iterations\", leave=False):\n",
    "        gofs.append([])\n",
    "        if k == (niterations - 1):\n",
    "            weights_second_last_iteration = weights.copy()\n",
    "            weights_to_average = []\n",
    "            \n",
    "        for j, unique_code in enumerate(unique_codes):\n",
    "            unique_code_weights, our_values_bin_idx = get_unique_code_weights(\n",
    "                unique_code, distributions, samples, weights, j, k\n",
    "            )\n",
    "            if k == (niterations - 1):\n",
    "                weights_to_average.append(unique_code_weights[our_values_bin_idx])\n",
    "        \n",
    "            weights *= unique_code_weights[our_values_bin_idx]\n",
    "            \n",
    "            gof = ((unique_code_weights[1:-1] - 1) ** 2).sum()\n",
    "            gofs[-1].append(gof)\n",
    "               \n",
    "            gofs_full.append([unique_code])\n",
    "            for unique_code_check in unique_codes:\n",
    "                unique_code_check_weights, _ = get_unique_code_weights(\n",
    "                    unique_code_check, distributions, samples, weights, 1, 1\n",
    "                )\n",
    "                gof = ((unique_code_check_weights[1:-1] - 1) ** 2).sum()\n",
    "                gofs_full[-1].append(gof)\n",
    "\n",
    "    weights_stacked = np.vstack(weights_to_average).mean(axis=0)\n",
    "    weights_final = weights_stacked * weights_second_last_iteration\n",
    "\n",
    "    gofs_full.append([\"Final iteration\"])\n",
    "    for unique_code_check in unique_codes:\n",
    "        unique_code_check_weights, _ = get_unique_code_weights(\n",
    "            unique_code_check, distributions, samples, weights_final, 1, 1\n",
    "        )\n",
    "        gof = ((unique_code_check_weights[1:-1] - 1) ** 2).sum()\n",
    "        gofs_full[-1].append(gof)\n",
    "\n",
    "    return (\n",
    "        weights_final, \n",
    "        pd.DataFrame(np.array(gofs), columns=unique_codes), \n",
    "        pd.DataFrame(np.array(gofs_full), columns=[\"Target marginal\"] + unique_codes)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb47287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_code_weights(unique_code, distributions, samples, weights, j, k):\n",
    "    bin_edges = distributions[unique_code][\"bins\"]\n",
    "    our_values = samples[unique_code].copy()\n",
    "\n",
    "    our_values_bin_counts, bin_edges_np = np.histogram(\n",
    "        our_values, bins=bin_edges\n",
    "    )\n",
    "    np.testing.assert_allclose(bin_edges, bin_edges_np)\n",
    "    assessed_ranges_bin_counts, _ = np.histogram(\n",
    "        distributions[unique_code][\"values\"], bins=bin_edges\n",
    "    )\n",
    "    \n",
    "    our_values_bin_idx = np.digitize(our_values, bins=bin_edges)\n",
    "\n",
    "    existing_weighted_bin_counts = np.nan * np.zeros(\n",
    "        our_values_bin_counts.shape[0]\n",
    "    )\n",
    "    for i in range(existing_weighted_bin_counts.shape[0]):\n",
    "        existing_weighted_bin_counts[i] = weights[\n",
    "            (our_values_bin_idx == i + 1)\n",
    "        ].sum()\n",
    "\n",
    "    if np.equal(j, 0) and np.equal(k, 0):\n",
    "        np.testing.assert_equal(\n",
    "            existing_weighted_bin_counts.sum(), our_values_bin_counts.sum()\n",
    "        )\n",
    "\n",
    "    unique_code_weights = np.nan * np.zeros(bin_edges.shape[0] + 1)\n",
    "\n",
    "    # existing_weighted_bin_counts[0] refers to samples outside the\n",
    "    # assessed range's lower bound. Accordingly, if `our_values` was\n",
    "    # digitized into a bin idx of zero, it should get a weight of zero.\n",
    "    unique_code_weights[0] = 0\n",
    "    # Similarly, if `our_values` was digitized into a bin idx greater\n",
    "    # than the number of bins then it was outside the assessed range\n",
    "    # so get a weight of zero.\n",
    "    unique_code_weights[-1] = 0\n",
    "    \n",
    "    for i in range(1, our_values_bin_counts.shape[0] + 1):\n",
    "        # the histogram idx is one less because digitize gives values in the\n",
    "        # range bin_edges[0] <= x < bin_edges[1] a digitized index of 1\n",
    "        histogram_idx = i - 1\n",
    "        if np.equal(assessed_ranges_bin_counts[histogram_idx], 0):\n",
    "            unique_code_weights[i] = 0\n",
    "        elif np.equal(existing_weighted_bin_counts[histogram_idx], 0):\n",
    "            # other variables force this box to be zero so just fill it with\n",
    "            # one\n",
    "            unique_code_weights[i] = 1\n",
    "        else:\n",
    "            unique_code_weights[i] = (\n",
    "                assessed_ranges_bin_counts[histogram_idx]\n",
    "                / existing_weighted_bin_counts[histogram_idx]\n",
    "            )\n",
    "            \n",
    "    return unique_code_weights, our_values_bin_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d348549",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, gofs, gofs_full = calculate_sample_weights(\n",
    "    ar_distributions, accepted, niterations=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1079528",
   "metadata": {},
   "outputs": [],
   "source": [
    "gofs_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_samples = int(np.floor(np.sum(np.minimum(weights, 1))))\n",
    "effective_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = []\n",
    "\n",
    "drawn_samples = accepted.sample(n=OUTPUT_ENSEMBLE_SIZE, replace=False, weights=weights, random_state=10099)\n",
    "draws.append((drawn_samples))\n",
    "\n",
    "#for i in tqdman.tqdm(range(10)):\n",
    "#    drawn_samples = accepted.sample(n=OUTPUT_ENSEMBLE_SIZE, replace=False, weights=weights, random_state=)\n",
    "    #     drawn_samples = samples_df.sample(n=10, replace=False, weights=weights)\n",
    "\n",
    "    #summary_table = get_summary_table(drawn_samples)\n",
    "\n",
    "    #score, coloured_df = utils.plotting.colour_df(summary_table, transpose=True)\n",
    "\n",
    "#    draws.append((drawn_samples))\n",
    "\n",
    "#sorted([v[1] for v in draws])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(draws[0]['ECS'])\n",
    "np.percentile(draws[0]['ECS'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69489d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(draws[0]['TCR'])\n",
    "np.percentile(draws[0]['TCR'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scatter(draws[0]['TCR'], draws[0]['ECS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(draws[0]['CO2 concentration'])\n",
    "np.percentile(draws[0]['CO2 concentration'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(draws[0]['temperature 1995-2014'])\n",
    "np.percentile(draws[0]['temperature 1995-2014'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(draws[0]['ERFari'])\n",
    "np.percentile(draws[0]['ERFari'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66348d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(draws[0]['ERFaci'])\n",
    "np.percentile(draws[0]['ERFaci'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b958730",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(draws[0]['ERFaci']+draws[0]['ERFari'])\n",
    "np.percentile(draws[0]['ERFaci']+draws[0]['ERFari'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efc0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(draws[0]['OHC'])\n",
    "np.percentile(draws[0]['OHC'], (5, 50, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scatter(draws[0]['TCR'], draws[0]['ERFaci']+draws[0]['ERFari'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "draws[0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc03bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gmst = pd.read_csv('../data/forcing/AR6_GMST.csv')\n",
    "gmst = df_gmst['gmst'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots()\n",
    "ax.fill_between(\n",
    "    np.arange(1850.5, 2101), \n",
    "    np.min(temp_in[:,draws[0].index]-temp_in[:51,draws[0].index].mean(axis=0), axis=1), \n",
    "    np.max(temp_in[:,draws[0].index]-temp_in[:51,draws[0].index].mean(axis=0), axis=1),\n",
    "    color='#000000',\n",
    "    alpha=0.2,\n",
    ")\n",
    "ax.fill_between(\n",
    "    np.arange(1850.5, 2101), \n",
    "    np.percentile(temp_in[:,draws[0].index]-temp_in[:51,draws[0].index].mean(axis=0), 5, axis=1), \n",
    "    np.percentile(temp_in[:,draws[0].index]-temp_in[:51,draws[0].index].mean(axis=0), 95, axis=1),\n",
    "    color='#000000',\n",
    "    alpha=0.2,\n",
    ")\n",
    "ax.fill_between(\n",
    "    np.arange(1850.5, 2101), \n",
    "    np.percentile(temp_in[:,draws[0].index]-temp_in[:51,draws[0].index].mean(axis=0), 16, axis=1), \n",
    "    np.percentile(temp_in[:,draws[0].index]-temp_in[:51,draws[0].index].mean(axis=0), 84, axis=1),\n",
    "    color='#000000',\n",
    "    alpha=0.2,\n",
    ")\n",
    "ax.plot(\n",
    "    np.arange(1850.5, 2101), \n",
    "    np.median(temp_in[:,draws[0].index]-temp_in[:51,draws[0].index].mean(axis=0), axis=1), \n",
    "    color='#000000',\n",
    ")\n",
    "\n",
    "ax.plot(np.arange(1850.5, 2021), gmst, color='b')\n",
    "\n",
    "ax.set_xlim(1850,2100)\n",
    "ax.set_ylim(-0.6, 3.5)\n",
    "ax.axhline(0, color='k', ls=\":\", lw=0.5)\n",
    "pl.title('Temperature anomaly - constrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb01452",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/ar6_ensemble_batches_rcp/final.csv', sorted(draws[0].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b35564",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(temp_in[-1,draws[0].index]-temp_in[:51,draws[0].index].mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca42a84",
   "metadata": {},
   "source": [
    "# Run the three-layer IRM\n",
    "\n",
    "This notebook will demonstrate the inclusion of ocean heat uptake.\n",
    "\n",
    "We will use example forcing from RFMIP to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8fba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "import scipy.linalg\n",
    "import scipy.stats\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71709502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    os.path.join(\"..\", \"data\", \"calibration\", \"4xCO2_cummins.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c951fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = df['model'].unique()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e60d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "for model in models:\n",
    "    params[model] = {}\n",
    "    for run in df.loc[df['model']==model, 'run']:\n",
    "        condition = (df['model']==model) & (df['run']==run)\n",
    "        params[model][run] = {}\n",
    "        params[model][run]['gamma_autocorrelation'] = df.loc[condition, 'gamma'].values[0]\n",
    "        params[model][run]['ocean_heat_capacity'] = df.loc[condition, 'C1':'C3'].values.squeeze()\n",
    "        params[model][run]['ocean_heat_transfer'] = df.loc[condition, 'kappa1':'kappa3'].values.squeeze()\n",
    "        params[model][run]['deep_ocean_efficacy'] = df.loc[condition, 'epsilon'].values[0]\n",
    "        params[model][run]['sigma_eta'] = df.loc[condition, 'sigma_eta'].values[0]\n",
    "        params[model][run]['sigma_xi'] = df.loc[condition, 'sigma_xi'].values[0]\n",
    "        params[model][run]['forcing_4co2'] = df.loc[condition, 'F_4xCO2'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16bafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this needs to be imported from 020\n",
    "\n",
    "def ebm3_to_irm3(params):\n",
    "    \"\"\"Converts the three-layer energy balance to impulse response form.\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    params : dict\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    params : dict\n",
    "    \"\"\"\n",
    "    \n",
    "    # unpack parameters\n",
    "    ocean_heat_capacity = params['ocean_heat_capacity']\n",
    "    ocean_heat_transfer = params['ocean_heat_transfer']\n",
    "    deep_ocean_efficacy = params['deep_ocean_efficacy']\n",
    "    forcing_4co2 = params.get('forcing_4co2', None)\n",
    "    \n",
    "    nbox = len(ocean_heat_capacity)  # should be 3\n",
    "    \n",
    "    # Define the matrix of differential equations\n",
    "    eb_matrix = np.array(\n",
    "        [\n",
    "            [\n",
    "                -(ocean_heat_transfer[0]+ocean_heat_transfer[1])/ocean_heat_capacity[0],\n",
    "                ocean_heat_transfer[1]/ocean_heat_capacity[0], \n",
    "                0\n",
    "            ],\n",
    "            [\n",
    "                ocean_heat_transfer[1]/ocean_heat_capacity[1],\n",
    "                -(ocean_heat_transfer[1]+deep_ocean_efficacy*ocean_heat_transfer[2])/ocean_heat_capacity[1],\n",
    "                deep_ocean_efficacy*ocean_heat_transfer[2]/ocean_heat_capacity[1]\n",
    "            ],\n",
    "            [\n",
    "                0, \n",
    "                ocean_heat_transfer[2]/ocean_heat_capacity[2],\n",
    "                -ocean_heat_transfer[2]/ocean_heat_capacity[2]\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Define the forcing vector\n",
    "    forcing_vector = np.array([1/ocean_heat_capacity[0], 0, 0])\n",
    "    \n",
    "    # Prepend eb_matrix with stochastic terms if this is a stochastic run: Cummins et al. (2020) eqs. 13 and 14\n",
    "    if stochastic_run:\n",
    "        eb_matrix = np.insert(eb_matrix, 0, np.zeros(nbox), axis=0)\n",
    "        prepend_col = np.zeros(nmatrix)\n",
    "        prepend_col[0] = -gamma_autocorrelation\n",
    "        prepend_col[1] = 1/ocean_heat_capacity[0]\n",
    "        eb_matrix = np.insert(eb_matrix, 0, prepend_col, axis=1)\n",
    "        forcing_vector = np.zeros(nmatrix)\n",
    "        forcing_vector[0] = gamma_autocorrelation\n",
    "    \n",
    "    # Calculate the matrix exponential\n",
    "    eb_matrix_d = scipy.linalg.expm(eb_matrix)\n",
    "    \n",
    "    # Solve for temperature\n",
    "    forcing_vector_d = scipy.linalg.solve(eb_matrix, (eb_matrix_d - np.identity(nmatrix)) @ forcing_vector)\n",
    "    \n",
    "    # define stochastic matrix\n",
    "    w_d = np.zeros((n_timesteps, nbox))\n",
    "    \n",
    "    # stochastic stuff\n",
    "    if stochastic_run:\n",
    "        Q = np.zeros((nmatrix, nmatrix))\n",
    "        Q[0,0] = sigma_eta**2\n",
    "        Q[1,1] = (sigma_xi/ocean_heat_capacity[0])**2\n",
    "        ## use Van Loan (1978) to compute the matrix exponential\n",
    "        H = np.zeros((nmatrix*2, nmatrix*2))\n",
    "        H[:4,:4] = -eb_matrix\n",
    "        H[:4,4:] = Q\n",
    "        H[4:,4:] = eb_matrix.T\n",
    "        G = scipy.linalg.expm(H)\n",
    "        Q_d = G[4:,4:].T @ G[:4,4:]\n",
    "        Q_d = Q_d.astype(np.float64)\n",
    "        w_d = scipy.stats.multivariate_normal.rvs(size=n_timesteps, mean=np.zeros(nmatrix), cov=Q_d, random_state=seed)\n",
    "    solution = np.zeros((n_timesteps, nmatrix))\n",
    "    for i in range(1, n_timesteps):\n",
    "        solution[i, :] = eb_matrix_d @ solution[i-1, :] + forcing_vector_d * forcing[i-1] + w_d[i-1, :]\n",
    "    \n",
    "    if stochastic_run:\n",
    "        temperature = solution[:, 1:]\n",
    "        results['stochastic_forcing'] = solution[:, 0]\n",
    "    else:\n",
    "        temperature = solution\n",
    "    toa_imbalance = forcing - ocean_heat_transfer[0]*temperature[:,0] + (1 - deep_ocean_efficacy) * ocean_heat_transfer[2] * (temperature[:,1] - temperature[:,2])\n",
    "    results['ocean_heat_content_change'] = np.cumsum(toa_imbalance) * EARTH_RADIUS**2 * 4 * np.pi * SECONDS_PER_YEAR\n",
    "    results['temperature'] = temperature\n",
    "    results['toa_imbalance'] = toa_imbalance\n",
    "    \n",
    "    return results\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "def threelayermodel(forcing, params):\n",
    "    # define results dict\n",
    "    results = {}\n",
    "    \n",
    "    # unpack parameters\n",
    "    ocean_heat_capacity = params['ocean_heat_capacity']\n",
    "    ocean_heat_transfer = params['ocean_heat_transfer']\n",
    "    deep_ocean_efficacy = params['deep_ocean_efficacy']\n",
    "    forcing_4co2 = params.get('forcing_4co2', None)\n",
    "    gamma_autocorrelation = params.get('gamma_autocorrelation', None)\n",
    "    sigma_eta = params.get('sigma_eta', None)\n",
    "    sigma_xi = params.get('sigma_xi', None)\n",
    "    seed = params.get('seed', None)\n",
    "\n",
    "    nbox = len(ocean_heat_capacity)\n",
    "    n_timesteps = len(forcing)\n",
    "    \n",
    "    # check if deterministic run\n",
    "    stochastic_run = True\n",
    "    if None in (gamma_autocorrelation, sigma_eta, sigma_xi):\n",
    "        stochastic_run = False\n",
    "    nmatrix = nbox + stochastic_run\n",
    "    \n",
    "    # Define the matrix of differential equations\n",
    "    eb_matrix = np.array(\n",
    "        [\n",
    "            [\n",
    "                -(ocean_heat_transfer[0]+ocean_heat_transfer[1])/ocean_heat_capacity[0],\n",
    "                ocean_heat_transfer[1]/ocean_heat_capacity[0], \n",
    "                0\n",
    "            ],\n",
    "            [\n",
    "                ocean_heat_transfer[1]/ocean_heat_capacity[1],\n",
    "                -(ocean_heat_transfer[1]+deep_ocean_efficacy*ocean_heat_transfer[2])/ocean_heat_capacity[1],\n",
    "                deep_ocean_efficacy*ocean_heat_transfer[2]/ocean_heat_capacity[1]\n",
    "            ],\n",
    "            [\n",
    "                0, \n",
    "                ocean_heat_transfer[2]/ocean_heat_capacity[2],\n",
    "                -ocean_heat_transfer[2]/ocean_heat_capacity[2]\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # calculate the eigenvectors and eigenvalues, these are the timescales of responses\n",
    "    eb_matrix_eigenvalues, eb_matrix_eigenvectors = scipy.linalg.eig(eb_matrix)\n",
    "    timescales = -1/(np.real(eb_matrix_eigenvalues))\n",
    "    response_coeffs = timescales * (eb_matrix_eigenvectors[0,:] * scipy.linalg.inv(eb_matrix_eigenvectors)[:,0]) / ocean_heat_capacity[0]\n",
    "\n",
    "    # calculate ECS and TCR from this parameter set; if 4xCO2 forcing is given\n",
    "    if forcing_4co2 is not None:\n",
    "        results['ecs'], results['tcr'] = emergent_parameters(response_coeffs, timescales, forcing_4co2)\n",
    "    \n",
    "    # Define the forcing vector\n",
    "    forcing_vector = np.array([1/ocean_heat_capacity[0], 0, 0])\n",
    "    \n",
    "    # Prepend eb_matrix with stochastic terms if this is a stochastic run: Cummins et al. (2020) eqs. 13 and 14\n",
    "    if stochastic_run:\n",
    "        eb_matrix = np.insert(eb_matrix, 0, np.zeros(nbox), axis=0)\n",
    "        prepend_col = np.zeros(nmatrix)\n",
    "        prepend_col[0] = -gamma_autocorrelation\n",
    "        prepend_col[1] = 1/ocean_heat_capacity[0]\n",
    "        eb_matrix = np.insert(eb_matrix, 0, prepend_col, axis=1)\n",
    "        forcing_vector = np.zeros(nmatrix)\n",
    "        forcing_vector[0] = gamma_autocorrelation\n",
    "    \n",
    "    # Calculate the matrix exponential\n",
    "    eb_matrix_d = scipy.linalg.expm(eb_matrix)\n",
    "    \n",
    "    # Solve for temperature\n",
    "    forcing_vector_d = scipy.linalg.solve(eb_matrix, (eb_matrix_d - np.identity(nmatrix)) @ forcing_vector)\n",
    "    \n",
    "    # define stochastic matrix\n",
    "    w_d = np.zeros((n_timesteps, nbox))\n",
    "    \n",
    "    # stochastic stuff\n",
    "    if stochastic_run:\n",
    "        Q = np.zeros((nmatrix, nmatrix))\n",
    "        Q[0,0] = sigma_eta**2\n",
    "        Q[1,1] = (sigma_xi/ocean_heat_capacity[0])**2\n",
    "        ## use Van Loan (1978) to compute the matrix exponential\n",
    "        H = np.zeros((nmatrix*2, nmatrix*2))\n",
    "        H[:4,:4] = -eb_matrix\n",
    "        H[:4,4:] = Q\n",
    "        H[4:,4:] = eb_matrix.T\n",
    "        G = scipy.linalg.expm(H)\n",
    "        Q_d = G[4:,4:].T @ G[:4,4:]\n",
    "        Q_d = Q_d.astype(np.float64)\n",
    "        w_d = scipy.stats.multivariate_normal.rvs(size=n_timesteps, mean=np.zeros(nmatrix), cov=Q_d, random_state=seed)\n",
    "    solution = np.zeros((n_timesteps, nmatrix))\n",
    "    for i in range(1, n_timesteps):\n",
    "        solution[i, :] = eb_matrix_d @ solution[i-1, :] + forcing_vector_d * forcing[i-1] + w_d[i-1, :]\n",
    "    \n",
    "    if stochastic_run:\n",
    "        temperature = solution[:, 1:]\n",
    "        results['stochastic_forcing'] = solution[:, 0]\n",
    "    else:\n",
    "        temperature = solution\n",
    "    toa_imbalance = forcing - ocean_heat_transfer[0]*temperature[:,0] + (1 - deep_ocean_efficacy) * ocean_heat_transfer[2] * (temperature[:,1] - temperature[:,2])\n",
    "    results['ocean_heat_content_change'] = np.cumsum(toa_imbalance) * EARTH_RADIUS**2 * 4 * np.pi * SECONDS_PER_YEAR\n",
    "    results['temperature'] = temperature\n",
    "    results['toa_imbalance'] = toa_imbalance\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forcing = pd.read_csv(\n",
    "    os.path.join(\"..\", \"data\", \"rfmip-erf\", \"RFMIP-ERF-tier2.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    forcing = df_forcing['%s TOT' % model].values\n",
    "    results[model] = threelayermodel(forcing, params[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7eab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    pl.plot(np.arange(1850, 2101), results[model]['temperature'][:,0], label=model)\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(model, results[model]['ecs'], results[model]['tcr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b228cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['HadGEM3-GC31-LL']['temperature'][160:170,0] - np.mean(results['HadGEM3-GC31-LL']['temperature'][:51,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c414876",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(np.arange(1850, 2015), results['HadGEM3-GC31-LL']['temperature'][:165,0])\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb98ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to see what an ensemble looks like!\n",
    "n_ens = 100\n",
    "\n",
    "ens = {}\n",
    "for im, model in tqdm(enumerate(models)):\n",
    "    ens[model] = {}\n",
    "    for i in tqdm(range(n_ens), leave=False):\n",
    "        params[model]['seed'] = im*1000+i\n",
    "        forcing = df_forcing['%s TOT' % model].values\n",
    "        ens[model][i] = threelayermodel(forcing, params[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data_output/branch_points.json', 'r') as f:\n",
    "    branch_points = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f07ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "piControls = dict.fromkeys(models, 'r1i1p1f1')\n",
    "piControls.update(dict.fromkeys(['CNRM-CM6-1'], 'r1i1p1f2'))\n",
    "piControls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip6_results = {}\n",
    "cmip6_results['temperature'] = {}\n",
    "cmip6_results['toa_imbalance'] = {}\n",
    "\n",
    "for model in models:\n",
    "    cmip6_results['temperature'][model] = {}\n",
    "    cmip6_results['toa_imbalance'][model] = {}\n",
    "    \n",
    "    control_df = pd.read_csv('../../data_output/cmip6/%s/%s/piControl.csv' % (model, piControls[model]))\n",
    "    control_tas = control_df['tas'].values\n",
    "    control_rsdt = control_df['rsdt'].values\n",
    "    control_rsut = control_df['rsut'].values\n",
    "    control_rlut = control_df['rlut'].values\n",
    "\n",
    "    for run in branch_points['historical'][model]:\n",
    "        # Define 251 time steps but don't fill them all if ssp245 not available\n",
    "        run_df = pd.read_csv('../../data_output/cmip6/%s/%s/historical.csv' % (model, run))\n",
    "        cmip6_results['temperature'][model][run] = np.ones(251) * np.nan\n",
    "        cmip6_results['toa_imbalance'][model][run] = np.ones(251) * np.nan\n",
    "        \n",
    "        cmip6_results['temperature'][model][run][:165] = (\n",
    "            run_df['tas'].values - \n",
    "            control_tas[branch_points['historical'][model][run]:branch_points['historical'][model][run]+165]\n",
    "        )\n",
    "        cmip6_results['toa_imbalance'][model][run][:165] = (\n",
    "            run_df['rsdt'].values - run_df['rsut'].values - run_df['rlut'].values - (\n",
    "                control_rsdt[branch_points['historical'][model][run]:branch_points['historical'][model][run]+165] -\n",
    "                control_rsut[branch_points['historical'][model][run]:branch_points['historical'][model][run]+165] - \n",
    "                control_rlut[branch_points['historical'][model][run]:branch_points['historical'][model][run]+165]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # check to see if a continuation ssp245 run exists\n",
    "        try:\n",
    "            run_df = pd.read_csv('../../data_output/cmip6/%s/%s/ssp245.csv' % (model, run))\n",
    "            nyears_ssp245 = np.min((86, len(run_df)))\n",
    "            cmip6_results['temperature'][model][run][165:165+nyears_ssp245] = (\n",
    "                run_df['tas'].values - \n",
    "                control_tas[branch_points['historical'][model][run]+165:branch_points['historical'][model][run]+165+nyears_ssp245]\n",
    "            )\n",
    "            cmip6_results['toa_imbalance'][model][run][165:165+nyears_ssp245] = (\n",
    "                run_df['rsdt'].values - run_df['rsut'].values - run_df['rlut'].values - (\n",
    "                    control_rsdt[branch_points['historical'][model][run]+165:branch_points['historical'][model][run]+165+nyears_ssp245] -\n",
    "                    control_rsut[branch_points['historical'][model][run]+165:branch_points['historical'][model][run]+165+nyears_ssp245] - \n",
    "                    control_rlut[branch_points['historical'][model][run]+165:branch_points['historical'][model][run]+165+nyears_ssp245]\n",
    "                )\n",
    "            )\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d50ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(2,4, figsize=(16,9))\n",
    "for im, model in enumerate(models):\n",
    "    for i in range(n_ens):\n",
    "        ax[im//4,im%4].plot(np.arange(1850, 2101), ens[model][i]['temperature'][:,0], color='k', alpha=0.2)\n",
    "    for run in branch_points['historical'][model]:\n",
    "        ax[im//4,im%4].plot(np.arange(1850, 2101), cmip6_results['temperature'][model][run], color='r', alpha=0.5)\n",
    "    ax[im//4,im%4].set_xlim(1850,2100)\n",
    "    ax[im//4,im%4].set_ylim(-1,6)\n",
    "    ax[im//4,im%4].grid()\n",
    "    ax[im//4,im%4].set_title(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(2,4, figsize=(16,9))\n",
    "for im, model in enumerate(models):\n",
    "    for i in range(n_ens):\n",
    "        ax[im//4,im%4].plot(np.arange(1850, 2101), ens[model][i]['toa_imbalance'], color='k', alpha=0.2)\n",
    "    for run in branch_points['historical'][model]:\n",
    "        ax[im//4,im%4].plot(np.arange(1850, 2101), cmip6_results['toa_imbalance'][model][run], color='r', alpha=0.5)\n",
    "    ax[im//4,im%4].set_xlim(1850,2100)\n",
    "    ax[im//4,im%4].set_ylim(-2,3)\n",
    "    ax[im//4,im%4].grid()\n",
    "    ax[im//4,im%4].set_title(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bb29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(2,4, figsize=(16,9))\n",
    "for im, model in enumerate(models):\n",
    "    for i in range(n_ens):\n",
    "        ax[im//4,im%4].plot(np.arange(1850, 2101), ens[model][i]['ocean_heat_content_change'], color='k', alpha=0.2)\n",
    "#     for run in branch_points['historical'][model]:\n",
    "#        ax[im//4,im%4].plot(np.arange(1850, 2015), cmip6_results['toa_imbalance'][model][run], color='r', alpha=0.1)\n",
    "    ax[im//4,im%4].set_xlim(1850,2100)\n",
    "    ax[im//4,im%4].set_ylim(-5e23, 3.5e24)\n",
    "    ax[im//4,im%4].grid()\n",
    "    ax[im//4,im%4].set_title(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e78d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888c78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bb54f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
